{
  "model": "Attention Unet",
  "seed": 1,
  "pretrained": "",
  "ignore_label": 255,

  "training": {
    "batch_size": 2,
    "num_workers": 0,
    "optimizer": "SGD",
    "momentum": 0.9,
    "num_iterations": 1000000,
    "learning_rate": 0.001,
    "lr_schedule": "Poly",
    "lr_schedule_power": 0.9,
    "weight_decay": 5e-6,
    "use_sync_batchnorm": false,

    "lam": 0.9,
    "data": {
      "split_id_list": 0,
      "labeled_samples": 0,
      "input_size": "384,384",
      "scale": false,
      "crop": true
    },
    "source_dataset": {
    "name": "gta",
    "num_classes": 4
    },
    "unlabeled": {
      "train_unlabeled": true,
      "consistency_weight": 1,
      "consistency_loss": "CE",
      "pixel_weight": "threshold_uniform",
      "mix_mask": "class",
      "flip": false,
      "color_jitter": true,
      "blur": true
    }
  },

  "utils": {
    "save_checkpoint_every": 5000,
    "checkpoint_dir": "./saved",
    "val_per_iter": 5000,
    "tensorboard": false,
    "log_per_iter": 100,
    "save_best_model": true
  }
}
